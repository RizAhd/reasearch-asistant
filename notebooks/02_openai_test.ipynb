{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e786b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import arxiv\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b17df85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../backend/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc0be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13248412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded successfully!\n",
      "üìä Available APIs: OpenAI, Wikipedia, arXiv, NewsAPI\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Environment loaded successfully!\")\n",
    "print(f\"üìä Available APIs: OpenAI, Wikipedia, arXiv, NewsAPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc1e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikipedia(query: str, max_chars: int = 500) -> Optional[Dict]:\n",
    "    \"\"\"Fetch Wikipedia content using MediaWiki API\"\"\"\n",
    "    try:\n",
    "        # Clean query\n",
    "        clean_query = query.replace(\" \", \"_\")\n",
    "        \n",
    "        # MediaWiki API\n",
    "        api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"prop\": \"extracts|info\",\n",
    "            \"exintro\": True,\n",
    "            \"explaintext\": True,\n",
    "            \"titles\": clean_query,\n",
    "            \"inprop\": \"url\"\n",
    "        }\n",
    "        \n",
    "        headers = {'User-Agent': 'ResearchAssistant/1.0'}\n",
    "        response = requests.get(api_url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "            \n",
    "            for page_id, page_info in pages.items():\n",
    "                if page_id != \"-1\":  # Valid page\n",
    "                    content = page_info.get('extract', '')\n",
    "                    if len(content) > max_chars:\n",
    "                        content = content[:max_chars] + \"...\"\n",
    "                    \n",
    "                    return {\n",
    "                        \"title\": page_info.get('title'),\n",
    "                        \"content\": content,\n",
    "                        \"url\": f\"https://en.wikipedia.org/?curid={page_id}\",\n",
    "                        \"source\": \"Wikipedia\",\n",
    "                        \"type\": \"encyclopedia\"\n",
    "                    }\n",
    "        \n",
    "        # If direct page not found, try search\n",
    "        search_params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": query,\n",
    "            \"srlimit\": 1\n",
    "        }\n",
    "        \n",
    "        search_response = requests.get(api_url, params=search_params, headers=headers)\n",
    "        if search_response.status_code == 200:\n",
    "            search_data = search_response.json()\n",
    "            if search_data.get('query', {}).get('search'):\n",
    "                top_result = search_data['query']['search'][0]\n",
    "                return fetch_wikipedia(top_result['title'])\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Wikipedia error: {e}\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20718fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_arxiv(query: str, max_results: int = 2) -> List[Dict]:\n",
    "    \"\"\"Fetch academic papers from arXiv\"\"\"\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for paper in client.results(search):\n",
    "            # Clean summary\n",
    "            summary = paper.summary\n",
    "            summary = summary.replace('\\n', ' ').replace('  ', ' ')\n",
    "            if len(summary) > 300:\n",
    "                summary = summary[:300] + \"...\"\n",
    "            \n",
    "            results.append({\n",
    "                \"title\": paper.title,\n",
    "                \"content\": summary,\n",
    "                \"url\": paper.entry_id,\n",
    "                \"source\": \"arXiv\",\n",
    "                \"type\": \"academic\",\n",
    "                \"authors\": [str(author) for author in paper.authors[:3]],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\")\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"arXiv error: {e}\")\n",
    "        return []\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: NewsAPI Fetcher\n",
    "\n",
    "# %%\n",
    "def fetch_news(query: str, max_results: int = 2) -> List[Dict]:\n",
    "    \"\"\"Fetch news articles from NewsAPI\"\"\"\n",
    "    NEWS_API_KEY = os.getenv('NEWS_API_KEY')\n",
    "    if not NEWS_API_KEY:\n",
    "        print(\"‚ö†Ô∏è NewsAPI key not found\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        news_url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"apiKey\": NEWS_API_KEY,\n",
    "            \"pageSize\": max_results,\n",
    "            \"language\": \"en\",\n",
    "            \"sortBy\": \"relevancy\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(news_url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "            \n",
    "            results = []\n",
    "            for article in articles:\n",
    "                if article.get('title') and article.get('title') != \"[Removed]\":\n",
    "                    content = article.get('description') or article.get('content') or \"\"\n",
    "                    if len(content) > 200:\n",
    "                        content = content[:200] + \"...\"\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"title\": article['title'],\n",
    "                        \"content\": content,\n",
    "                        \"url\": article.get('url', '#'),\n",
    "                        \"source\": article.get('source', {}).get('name', 'Unknown'),\n",
    "                        \"type\": \"news\",\n",
    "                        \"published\": article.get('publishedAt', '')[:10]\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        else:\n",
    "            print(f\"NewsAPI error: HTTP {response.status_code}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"NewsAPI error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c99b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query: str, sources: List[Dict]) -> Dict:\n",
    "    \"\"\"Use OpenAI to synthesize information from all sources\"\"\"\n",
    "    \n",
    "    # Format sources for prompt\n",
    "    formatted_sources = \"\"\n",
    "    for i, source in enumerate(sources, 1):\n",
    "        formatted_sources += f\"\\n\\n[Source {i} - {source['source']}]\"\n",
    "        formatted_sources += f\"\\nTitle: {source['title']}\"\n",
    "        formatted_sources += f\"\\nContent: {source['content']}\"\n",
    "        formatted_sources += f\"\\nType: {source['type']}\"\n",
    "        if source.get('authors'):\n",
    "            formatted_sources += f\"\\nAuthors: {', '.join(source['authors'])}\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are a research assistant. Your task:\n",
    "1. Answer the user's question comprehensively\n",
    "2. Use ONLY information from the provided sources\n",
    "3. Cite sources as [1], [2], [3] etc.\n",
    "4. If information is contradictory, mention this\n",
    "5. If sources lack information, say so\n",
    "6. Format answer with clear paragraphs and bullet points where helpful\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Question: {query}\n",
    "\n",
    "Available Sources:{formatted_sources}\n",
    "\n",
    "Please provide a well-structured answer with citations:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"tokens_used\": response.usage.total_tokens,\n",
    "            \"model\": response.model\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        return {\n",
    "            \"answer\": f\"Error generating summary: {str(e)}\",\n",
    "            \"tokens_used\": 0,\n",
    "            \"model\": \"error\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6b8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_assistant(query: str) -> Dict:\n",
    "    \"\"\"Main function to orchestrate research\"\"\"\n",
    "    print(f\"üîç Researching: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Step 1: Fetch from all sources\n",
    "    print(\"üìö Gathering information from sources...\")\n",
    "    \n",
    "    # Fetch in sequence (to avoid rate limits)\n",
    "    wikipedia_data = fetch_wikipedia(query)\n",
    "    arxiv_data = fetch_arxiv(query)\n",
    "    news_data = fetch_news(query)\n",
    "    \n",
    "    # Combine all sources\n",
    "    all_sources = []\n",
    "    if wikipedia_data:\n",
    "        all_sources.append(wikipedia_data)\n",
    "    all_sources.extend(arxiv_data)\n",
    "    all_sources.extend(news_data)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(all_sources)} sources:\")\n",
    "    for i, source in enumerate(all_sources, 1):\n",
    "        print(f\"  {i}. {source['source']}: {source['title'][:50]}...\")\n",
    "    \n",
    "    if not all_sources:\n",
    "        return {\n",
    "            \"answer\": \"‚ùå No relevant sources found for your query.\",\n",
    "            \"sources\": [],\n",
    "            \"tokens_used\": 0\n",
    "        }\n",
    "\n",
    "        print(\"\\nü§ñ Generating comprehensive answer...\")\n",
    "    summary_result = generate_summary(query, all_sources)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": summary_result[\"answer\"],\n",
    "        \"sources\": all_sources,\n",
    "        \"tokens_used\": summary_result[\"tokens_used\"],\n",
    "        \"model\": summary_result.get(\"model\", \"gpt-3.5-turbo\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936cd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Researching: 'What is artificial intelligence?'\n",
      "--------------------------------------------------\n",
      "üìö Gathering information from sources...\n",
      "‚úÖ Found 5 sources:\n",
      "  1. Wikipedia: Artificial intelligence...\n",
      "  2. arXiv: The Artificial Scientist: Logicist, Emergentist, a...\n",
      "  3. arXiv: Compression, The Fermi Paradox and Artificial Supe...\n",
      "  4. The Next Web: A 2025 recap for Tech & AI...\n",
      "  5. Theregister.com: Recline of the machines: Terminator felled by dodg...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## ü§ñ Answer\n",
       "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence [1]. Here is a comprehensive understanding of artificial intelligence based on the provided sources:\n",
       "\n",
       "1. **Definition**: \n",
       "   - AI involves tasks such as learning, reasoning, problem-solving, perception, and decision-making.\n",
       "   - It is a field of research in computer science that focuses on developing methods and software that enable machines to perceive their environment and use learning and intelligence to achieve defined goals [1].\n",
       "\n",
       "2. **Types of AI**:\n",
       "   - **Artificial General Intelligence (AGI)**: This refers to AI that has the ability to understand, learn, and apply knowledge across different domains, similar to human intelligence. AGI is discussed in academic papers exploring different approaches to achieving it [2,3].\n",
       "   - **Generative AI**: Mentioned in a news article, generative AI was a significant trend in technology in the years leading up to 2025. It involves creating AI systems capable of generating content, such as images and text [4].\n",
       "\n",
       "3. **Challenges and Considerations**:\n",
       "   - **Communication and Control**: There are discussions about the challenges associated with communicating with and controlling AGI. This includes concerns about managing artificial super-intelligence and the implications of the Fermi Paradox [3].\n",
       "   - **Hybrid Approaches**: Some researchers argue that a unified or hybrid approach to AGI is necessary [2]. This suggests that a combination of different AI methodologies may be needed to achieve more advanced AI capabilities.\n",
       "\n",
       "4. **Recent Trends**:\n",
       "   - The year 2025 was highlighted as a significant period when technology, including AI, transitioned from a futuristic concept to a present reality. Developments in generative AI and platform innovation were notable during this time [4].\n",
       "   - However, news articles also humorously depict the challenges AI may face, such as the Terminator character needing a battery recharge [5].\n",
       "\n",
       "5. **Gaps in Information**:\n",
       "   - While the sources provide insights into the definition, types, challenges, and trends related to AI, there may be a lack of detailed information on specific AI technologies, applications, or breakthroughs in the field in recent years.\n",
       "\n",
       "In conclusion, artificial intelligence encompasses a broad range of capabilities that mimic human intelligence. Researchers are exploring various approaches, including AGI and generative AI, to advance the field further. Challenges related to communication, control, and hybrid AI approaches are topics of interest in the academic community, while practical applications of AI continue to evolve in technology trends."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## üìö Sources Used"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 1. Artificial intelligence\n",
       "    **Source:** Wikipedia (encyclopedia)\n",
       "    \n",
       "    **Content Preview:** Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\n",
       "High-profile applications of AI incl...\n",
       "    \n",
       "    **URL:** [Open Link](https://en.wikipedia.org/?curid=1164)\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 2. The Artificial Scientist: Logicist, Emergentist, and Universalist Approaches to Artificial General Intelligence\n",
       "    **Source:** arXiv (academic)\n",
       "    \n",
       "    **Content Preview:** We attempt to define what is necessary to construct an Artificial Scientist, explore and evaluate several approaches to artificial general intelligence (AGI) which may facilitate this, conclude that a unified or hybrid approach is necessary and explore two theories that satisfy this requirement to s...\n",
       "    \n",
       "    **URL:** [Open Link](http://arxiv.org/abs/2110.01831v1)\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 3. Compression, The Fermi Paradox and Artificial Super-Intelligence\n",
       "    **Source:** arXiv (academic)\n",
       "    \n",
       "    **Content Preview:** The following briefly discusses possible difficulties in communication with and control of an AGI (artificial general intelligence), building upon an explanation of The Fermi Paradox and preceding work on symbol emergence and artificial general intelligence. The latter suggests that to infer what so...\n",
       "    \n",
       "    **URL:** [Open Link](http://arxiv.org/abs/2110.01835v1)\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 4. A 2025 recap for Tech & AI\n",
       "    **Source:** The Next Web (news)\n",
       "    \n",
       "    **Content Preview:** 2025 was the year technology stopped being tomorrow‚Äôs promise and became today‚Äôs anchor. What began as a surge in generative AI and platform innovation two years prior crystallized this year into conc...\n",
       "    \n",
       "    **URL:** [Open Link](https://thenextweb.com/news/a-2025-recap-for-tech-ai)\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 5. Recline of the machines: Terminator felled by dodgy battery\n",
       "    **Source:** Theregister.com (news)\n",
       "    \n",
       "    **Content Preview:** The rise will be postponed until you hit F1 to continue\n",
       "Bork!Bork!Bork! The baddest of AI bad guys, the Terminator, has confirmed what the vast majority of IT professionals already know. The machines ...\n",
       "    \n",
       "    **URL:** [Open Link](https://www.theregister.com/2026/01/07/terminator_felled_by_dodgy_battery/)\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üìä Statistics\n",
       "- **Total Sources:** 5\n",
       "- **Tokens Used:** 1061\n",
       "- **Model:** gpt-3.5-turbo-0125\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_query = \"What is artificial intelligence?\"\n",
    "\n",
    "result = research_assistant(test_query)\n",
    "\n",
    "display(Markdown(f\"## ü§ñ Answer\\n{result['answer']}\"))\n",
    "\n",
    "display(Markdown(\"## üìö Sources Used\"))\n",
    "\n",
    "for i, source in enumerate(result['sources'], 1):\n",
    "    display(Markdown(f\"\"\"\n",
    "    ### {i}. {source['title']}\n",
    "    **Source:** {source['source']} ({source['type']})\n",
    "    \n",
    "    **Content Preview:** {source['content']}\n",
    "    \n",
    "    **URL:** [Open Link]({source['url']})\n",
    "    \"\"\"))\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "## üìä Statistics\n",
    "- **Total Sources:** {len(result['sources'])}\n",
    "- **Tokens Used:** {result['tokens_used']}\n",
    "- **Model:** {result.get('model', 'gpt-3.5-turbo')}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18338f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_test():\n",
    "    \"\"\"Interactive testing loop\"\"\"\n",
    "    print(\"üéØ Universal Research Assistant - Interactive Mode\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nüìù Enter your research question: \").strip()\n",
    "        \n",
    "        if query.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not query:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        result = research_assistant(query)\n",
    "        \n",
    "        # Display answer\n",
    "        print(\"\\n\" + \"ü§ñ ANSWER:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result['answer'])\n",
    "        \n",
    "        # Display source count\n",
    "        print(f\"\\nüìö Used {len(result['sources'])} sources\")\n",
    "        print(f\"‚ö° Used {result['tokens_used']} tokens\")\n",
    "        \n",
    "        # Show sources\n",
    "        if result['sources']:\n",
    "            print(\"\\nüìñ Sources:\")\n",
    "            for i, source in enumerate(result['sources'], 1):\n",
    "                print(f\"  {i}. [{source['source']}] {source['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df753184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Batch Testing Multiple Queries\n",
      "============================================================\n",
      "\n",
      "1. Query: 'What is machine learning?'\n",
      "üîç Researching: 'What is machine learning?'\n",
      "--------------------------------------------------\n",
      "üìö Gathering information from sources...\n",
      "‚úÖ Found 5 sources:\n",
      "  1. Wikipedia: Machine learning...\n",
      "  2. arXiv: Changing Data Sources in the Age of Machine Learni...\n",
      "  3. arXiv: DOME: Recommendations for supervised machine learn...\n",
      "  4. 9to5Mac: Apple shared ‚Äòbendgate‚Äô lessons as it helped small...\n",
      "  5. Search Engine Journal: 10 Hard Truths About PPC: Insights From Last Year‚Äô...\n",
      "   Sources: 5 | Tokens: 813\n",
      "   Answer preview: Machine learning (ML) is a field within artificial intelligence that focuses on the development and ...\n",
      "\n",
      "2. Query: 'Explain quantum computing'\n",
      "üîç Researching: 'Explain quantum computing'\n",
      "--------------------------------------------------\n",
      "üìö Gathering information from sources...\n",
      "‚úÖ Found 5 sources:\n",
      "  1. Wikipedia: Quantum computing...\n",
      "  2. arXiv: Tierkreis: A Dataflow Framework for Hybrid Quantum...\n",
      "  3. arXiv: Quantum Computing: Vision and Challenges...\n",
      "  4. Gizmodo.com: Privacy Coin Zcash Drops 20% as Core Dev Team Depa...\n",
      "  5. New Scientist: Our elegant universe: rethinking nature‚Äôs deepest ...\n",
      "   Sources: 5 | Tokens: 732\n",
      "   Answer preview: Quantum computing is a type of computing that leverages the principles of quantum mechanics to perfo...\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain quantum computing\",\n",
    "    \"Latest developments in renewable energy\",\n",
    "    \"What is climate change?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Batch Testing Multiple Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries[:2], 1):  # Test first 2\n",
    "    print(f\"\\n{i}. Query: '{query}'\")\n",
    "    result = research_assistant(query)\n",
    "    print(f\"   Sources: {len(result['sources'])} | Tokens: {result['tokens_used']}\")\n",
    "    print(f\"   Answer preview: {result['answer'][:100]}...\")\n",
    "    time.sleep(2)  # Avoid rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b2c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results exported to research_results.md\n"
     ]
    }
   ],
   "source": [
    "def export_results(result: Dict, format: str = \"markdown\"):\n",
    "    \"\"\"Export research results\"\"\"\n",
    "    if format == \"markdown\":\n",
    "        content = f\"# Research Results\\n\\n\"\n",
    "        content += f\"**Query:** {test_query}\\n\\n\"\n",
    "        content += f\"## Answer\\n{result['answer']}\\n\\n\"\n",
    "        content += f\"## Sources\\n\"\n",
    "        \n",
    "        for i, source in enumerate(result['sources'], 1):\n",
    "            content += f\"\\n### {i}. {source['title']}\\n\"\n",
    "            content += f\"- **Source:** {source['source']}\\n\"\n",
    "            content += f\"- **Type:** {source['type']}\\n\"\n",
    "            content += f\"- **URL:** {source['url']}\\n\"\n",
    "            content += f\"- **Preview:** {source['content']}\\n\"\n",
    "        \n",
    "        content += f\"\\n## Statistics\\n\"\n",
    "        content += f\"- Total Sources: {len(result['sources'])}\\n\"\n",
    "        content += f\"- Tokens Used: {result['tokens_used']}\\n\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open(\"research_results.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(\"‚úÖ Results exported to research_results.md\")\n",
    "        return content\n",
    "\n",
    "# Export the test results\n",
    "exported = export_results(result, \"markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb94654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Research Assistant - Quick Test\n",
      "==================================================\n",
      "\n",
      "Researching: 'what are the usesu pf you what will you can genearte'\n",
      "Fetching data from sources...\n",
      "\n",
      "üìö Checking sources...\n",
      "‚úÖ arXiv: Found academic papers\n",
      "\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "==================================================\n",
      "‚úÖ RESULT:\n",
      "==================================================\n",
      "\n",
      "Question: what are the usesu pf you what will you can genearte\n",
      "\n",
      "Answer: I'm sorry, but it seems there may be a typo or error in your question. Could you please provide more context or clarify your question so I can assist you better?\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv('backend/.env')\n",
    "\n",
    "# Check API keys\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ùå OpenAI API key missing! Add to backend/.env\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"üîç Research Assistant - Quick Test\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with a simple question\n",
    "test_question = input(\"\\nüìù Enter your question (or press Enter for default): \").strip()\n",
    "\n",
    "if not test_question:\n",
    "    test_question = \"What is artificial intelligence?\"\n",
    "    print(f\"Using default: '{test_question}'\")\n",
    "\n",
    "print(f\"\\nResearching: '{test_question}'\")\n",
    "print(\"Fetching data from sources...\")\n",
    "\n",
    "# Import our functions\n",
    "try:\n",
    "    # Add backend to path\n",
    "    sys.path.append('backend')\n",
    "    \n",
    "    # Create a simple test class\n",
    "    import requests\n",
    "    import arxiv\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    # Simple Wikipedia fetch\n",
    "    def get_wikipedia(query):\n",
    "        try:\n",
    "            api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "            params = {\n",
    "                \"action\": \"query\",\n",
    "                \"format\": \"json\",\n",
    "                \"prop\": \"extracts\",\n",
    "                \"exintro\": True,\n",
    "                \"explaintext\": True,\n",
    "                \"titles\": query.replace(\" \", \"_\")\n",
    "            }\n",
    "            response = requests.get(api_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "                for page_id, page_info in pages.items():\n",
    "                    if page_id != \"-1\":\n",
    "                        return page_info.get('extract', '')[:300]\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    # Simple OpenAI answer\n",
    "    def get_answer(question, context=None):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "        ]\n",
    "        \n",
    "        if context:\n",
    "            messages.insert(1, {\"role\": \"assistant\", \"content\": f\"Context: {context}\"})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    # Get data\n",
    "    print(\"\\nüìö Checking sources...\")\n",
    "    \n",
    "    # Try Wikipedia\n",
    "    wiki_content = get_wikipedia(test_question)\n",
    "    if wiki_content:\n",
    "        print(\"‚úÖ Wikipedia: Found information\")\n",
    "    \n",
    "    # Try arXiv\n",
    "    try:\n",
    "        arxiv_client = arxiv.Client()\n",
    "        search = arxiv.Search(query=test_question, max_results=1)\n",
    "        results = list(arxiv_client.results(search))\n",
    "        if results:\n",
    "            print(\"‚úÖ arXiv: Found academic papers\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Get answer\n",
    "    print(\"\\nü§ñ Generating answer...\")\n",
    "    answer = get_answer(test_question, wiki_content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"‚úÖ RESULT:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nQuestion: {test_question}\")\n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    print(\"\\nMake sure all packages are installed:\")\n",
    "    print(\"pip install openai requests arxiv python-dotenv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
